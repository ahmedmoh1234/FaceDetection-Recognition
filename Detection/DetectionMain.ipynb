{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import skimage as sk\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "\n",
    "\n",
    "from unitTesting import UnitTest\n",
    "import adaboost.adaboost as ab\n",
    "import utilitis as ut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread('./test.jpg')\n",
    "img = rgb2gray(img)\n",
    "unitTesting = UnitTest(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#load positive dataset\n",
    "try:\n",
    "    print(\"Loading positive dataset...\")\n",
    "    positiveDataset = np.load(\"./Dataset/posTrain.npy\")\n",
    "except:\n",
    "    print(\"No dataset found, creating new dataset...\")\n",
    "    positiveDataset = np.load(\"./Dataset/olivetti_faces.npy\")\n",
    "    personID = np.load(\"./Dataset/olivetti_faces_target.npy\")\n",
    "\n",
    "\n",
    "    #resize images to 24x24\n",
    "    newPositiveDataset = np.empty(shape=(positiveDataset.shape[0], 24, 24))\n",
    "    for i in range(len(positiveDataset)):\n",
    "        newImg = np.array(positiveDataset[i])\n",
    "        \n",
    "        finalImg = resize(newImg, (24, 24))\n",
    "        newPositiveDataset[i] = finalImg\n",
    "\n",
    "    positiveDataset = newPositiveDataset\n",
    "\n",
    "    # for i in range(10):\n",
    "    #     io.imshow(positiveDataset[i])\n",
    "    #     io.show()\n",
    "\n",
    "    # print(positiveDataset.shape)\n",
    "\n",
    "    \n",
    "\n",
    "    # np.save(\"./Dataset/positiveDataset.npy\", positiveDataset)\n",
    "    # print(\"Positive Dataset saved\")\n",
    "\n",
    "#loading negative dataset\n",
    "try:\n",
    "    print(\"Loading negative dataset...\")\n",
    "    negativeDataset = np.load(\"./Dataset/negTrain.npy\")\n",
    "except:\n",
    "    print(\"No dataset found, creating new dataset...\")\n",
    "    directory = \"./Dataset/NegativeSet\"\n",
    "    negativeDataset = np.empty(shape=(len(os.listdir(directory)), 24, 24))\n",
    "    i = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            curImg = io.imread(os.path.join(directory, filename), as_gray=True)\n",
    "            newImg = resize(curImg, (24, 24))\n",
    "            negativeDataset[i] = newImg\n",
    "            i += 1\n",
    "    # negativeDataset = negativeDataset.reshape(len(os.listdir(directory)), 64, 64)\n",
    "    # print(negativeDataset.shape)\n",
    "    # np.save(\"./Dataset/negativeDataset.npy\", negativeDataset)\n",
    "    # print(\"Negative Dataset saved\")\n",
    "\n",
    "\n",
    "\n",
    "posDataset, negDataset = ut.preprocessImages(positiveDataset, negativeDataset)\n",
    "\n",
    "print(f\"Positive Dataset Shape: {posDataset.shape}\")\n",
    "print(f\"Negative Dataset Shape: {negDataset.shape}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minFeatureWidth = 1\n",
    "maxFeatureWidth = 20\n",
    "minFeatureHeight = 1\n",
    "maxFeatureHeight = 20\n",
    "nClassifiers = 10000\n",
    "threshold = 0\n",
    "\n",
    "classifiersToBeUsed = []\n",
    "try :\n",
    "    print(\"Loading classifiers...\")\n",
    "    classifiersToBeUsed = np.load(\"./classifiers.npy\", allow_pickle=True)\n",
    "except Exception as e:\n",
    "    # print(e)\n",
    "    print(\"No classifiers found, creating new classifiers...\")\n",
    "    classifier = ab.AdaBoost()\n",
    "    start = time.time()\n",
    "    classifiersToBeUsed = classifier.learn(posDataset, negDataset,threshold,minFeatureWidth,minFeatureHeight,maxFeatureWidth,maxFeatureHeight, nClassifiers)\n",
    "    end = time.time()\n",
    "    classifiersToBeUsed = np.array(classifiersToBeUsed)\n",
    "    np.save(\"./classifiers\"+str(nClassifiers)+\"-\" + str(threshold)+ \"-\"+str(minFeatureWidth)+\"-\" + str(maxFeatureWidth)+ \".npy\", classifiersToBeUsed)\n",
    "    print(\"Time taken to train the classifier: \", end-start)\n",
    "\n",
    "print(\"Classifiers loaded successfully\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataSet = np.load(\"./Dataset/testMix.npy\")\n",
    "testDataSetTarget = np.load(\"./Dataset/testTargets.npy\")\n",
    "#convert to int \n",
    "testDataSetTarget = testDataSetTarget.astype(int)\n",
    "\n",
    "print(f\"Test Dataset Shape: {testDataSet.shape}\")\n",
    "\n",
    "#get integral images\n",
    "ii = np.array([ut.integralImage(test) for test in testDataSet])\n",
    "\n",
    "i = 0\n",
    "correctCount = 0\n",
    "firstWrong = 5\n",
    "facesCount = 0\n",
    "correctFacesCount = 0\n",
    "correctNonFacesCount = 0\n",
    "nonFacesCount = 0\n",
    "for test in ii:\n",
    "    predicted = ut.getVotes(np.array(classifiersToBeUsed), test)\n",
    "    if predicted == testDataSetTarget[i]:\n",
    "        correctCount += 1\n",
    "        if predicted == 1:\n",
    "            correctFacesCount += 1\n",
    "        else:\n",
    "            correctNonFacesCount += 1\n",
    "    else:\n",
    "        if firstWrong > 0:\n",
    "            print(\"Predicted: \", predicted)\n",
    "            print(\"Target: \", testDataSetTarget[i])\n",
    "            # io.imshow(testDataSet[i])\n",
    "            # io.show()\n",
    "            firstWrong -= 1\n",
    "    if testDataSetTarget[i] == 1:\n",
    "        facesCount += 1\n",
    "    if testDataSetTarget[i] == 0:\n",
    "        nonFacesCount += 1\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print(\"Accuracy: \", correctCount/len(testDataSet) * 100, \"%\")\n",
    "print(f\"Faces detected: {correctFacesCount} / {facesCount} , Accuracy: {correctFacesCount/facesCount * 100}%\")\n",
    "print(f\"Non Faces detected: {correctNonFacesCount} / {nonFacesCount} , Accuracy: {correctNonFacesCount/nonFacesCount * 100}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img2) -> list:\n",
    "    img = np.copy(img2)\n",
    "    img = rgb2gray(img)\n",
    "    img = img/img.max()\n",
    "    img = img / np.var(img)\n",
    "\n",
    "\n",
    "    ii = ut.integralImage(img)\n",
    "    imgHeight, imgWidth = img.shape\n",
    "\n",
    "    if imgHeight < 24 or imgWidth < 24:\n",
    "        return []\n",
    "\n",
    "    #scaling features\n",
    "    maxScaleFactor = min(imgHeight/24, imgWidth/24)\n",
    "\n",
    "\n",
    "    \n",
    "    detectedFaces = []\n",
    "\n",
    "    try:\n",
    "        scaledFeatures = np.load(\"./scaledClassifiers.npy\", allow_pickle=True)\n",
    "        print(\"Scaled features loaded successfully\")\n",
    "    except:\n",
    "        print(\"No scaled features found, creating new scaled features...\")\n",
    "        scaleFactorStart = 10\n",
    "        scaleFactor = scaleFactorStart\n",
    "        shiftValue = 1\n",
    "        finalScaledFeatures = [] \n",
    "        while scaleFactor <= maxScaleFactor:\n",
    "            scaledFeatures = copy.deepcopy(classifiersToBeUsed)\n",
    "            scaledFeatures = [sf * float(scaleFactor) for sf in scaledFeatures]\n",
    "            for x in range(0, int(imgWidth - (24 * scaleFactor)), int(np.round(shiftValue * scaleFactor)) ):\n",
    "                scaledFeatures2 = copy.deepcopy(scaledFeatures)\n",
    "                scaledFeatures2 = [sf + (x,0) for sf in scaledFeatures2]\n",
    "                for y in range(0, int(imgHeight - (24 * scaleFactor)), int(np.round(shiftValue * scaleFactor))):\n",
    "                    # print(f\"scale factor: {scaleFactor}, x: {x}, y: {y}\")\n",
    "                    predicted = ut.getVotes(scaledFeatures2, ii)\n",
    "                    if predicted == 1:\n",
    "                        detectedFaces.append([x, y, scaleFactor])\n",
    "                    finalScaledFeatures.append(scaledFeatures2)\n",
    "                    scaledFeatures2 = [sf + (0,int(shiftValue * scaleFactor)) for sf in scaledFeatures2]\n",
    "            print(f\"finished scale factor: {scaleFactor}\")\n",
    "            scaleFactor += 1.25\n",
    "        np.save(\"./scaledClassifiers\" + str(scaleFactorStart) + \".npy\", np.array(finalScaledFeatures))\n",
    "        print(\"Scaled features saved successfully\")\n",
    "\n",
    "    \n",
    "    \n",
    "    return detectedFaces\n",
    "\n",
    "\n",
    "\n",
    "img = io.imread(\"./naderTest.jpg\")\n",
    "\n",
    "detectedFaces = predict(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawRect(img2, x, y, scaleFactor):\n",
    "    img = np.copy(img2)\n",
    "    img = img/img.max()\n",
    "    if len(img.shape) == 3:\n",
    "        img = rgb2gray(img)\n",
    "    # print(img.shape)\n",
    "    imgHeight, imgWidth = img.shape\n",
    "    x = int(x)\n",
    "    y = int(y)\n",
    "    scaleFactor = int(scaleFactor)\n",
    "    for i in range(x, x + (24 * scaleFactor)):\n",
    "        if i < imgWidth and y < imgHeight:\n",
    "            img[y][i] = 1\n",
    "        if i < imgWidth and y + (24 * scaleFactor) < imgHeight:\n",
    "            img[y + (24 * scaleFactor)][i] = 1\n",
    "    for i in range(y, y + (24 * scaleFactor)):\n",
    "        if i < imgHeight and x < imgWidth:\n",
    "            img[i][x] = 1\n",
    "        if i < imgHeight and x + (24 * scaleFactor) < imgWidth:\n",
    "            img[i][x + (24 * scaleFactor)] = 1\n",
    "    return img\n",
    "\n",
    "if len(detectedFaces) > 0:\n",
    "    print(f\"Faces detected: {len(detectedFaces)}\")\n",
    "    for face in detectedFaces:\n",
    "        img = drawRect(img, face[0], face[1], face[2])\n",
    "    io.imshow(img)\n",
    "    io.imsave(\"./naderTestDetected.jpg\", img)\n",
    "else:\n",
    "    print(\"No faces detected\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22323b844011101ed249661b7dd2cae934f6b78b31436e3431524c9d958c4c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
