{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import skimage as sk\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "from unitTesting import UnitTest\n",
    "import adaboost.adaboost as ab\n",
    "import utilitis as ut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral image test PASSED\n",
      "Total number of features = 273312\n",
      "Determine features test FAILED. No of features : 273,312\n",
      "Calculate sum test 1 PASSED\n",
      "Calculate sum test 2 PASSED\n",
      "Calculate sum test 3 PASSED\n",
      "Feature value test 1 PASSED\n",
      "Feature value test 2 PASSED\n"
     ]
    }
   ],
   "source": [
    "img = io.imread('./test.jpg')\n",
    "img = rgb2gray(img)\n",
    "unitTesting = UnitTest(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#load positive dataset\n",
    "try:\n",
    "    print(\"Loading positive dataset...\")\n",
    "    positiveDataset = np.load(\"./Dataset/positiveDataset.npy\")\n",
    "except:\n",
    "    print(\"No dataset found, creating new dataset...\")\n",
    "    positiveDataset = np.load(\"./Dataset/olivetti_faces.npy\")\n",
    "    personID = np.load(\"./Dataset/olivetti_faces_target.npy\")\n",
    "\n",
    "\n",
    "    #resize images to 24x24\n",
    "    newPositiveDataset = np.empty(shape=(positiveDataset.shape[0], 24, 24))\n",
    "    for i in range(len(positiveDataset)):\n",
    "        newImg = np.array(positiveDataset[i])\n",
    "        \n",
    "        finalImg = resize(newImg, (24, 24))\n",
    "        newPositiveDataset[i] = finalImg\n",
    "\n",
    "    positiveDataset = newPositiveDataset\n",
    "\n",
    "    # for i in range(10):\n",
    "    #     io.imshow(positiveDataset[i])\n",
    "    #     io.show()\n",
    "\n",
    "    # print(positiveDataset.shape)\n",
    "\n",
    "    \n",
    "\n",
    "    np.save(\"./Dataset/positiveDataset.npy\", positiveDataset)\n",
    "\n",
    "#loading negative dataset\n",
    "try:\n",
    "    print(\"Loading negative dataset...\")\n",
    "    negativeDataset = np.load(\"./Dataset/negativeDataset.npy\")\n",
    "except:\n",
    "    print(\"No dataset found, creating new dataset...\")\n",
    "    directory = \"./Dataset/NegativeSet\"\n",
    "    negativeDataset = np.empty(shape=(len(os.listdir(directory)), 24, 24))\n",
    "    i = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            curImg = io.imread(os.path.join(directory, filename), as_gray=True)\n",
    "            newImg = resize(curImg, (24, 24))\n",
    "            negativeDataset[i] = newImg\n",
    "            i += 1\n",
    "    # negativeDataset = negativeDataset.reshape(len(os.listdir(directory)), 64, 64)\n",
    "    # print(negativeDataset.shape)\n",
    "    np.save(\"./Dataset/negativeDataset.npy\", negativeDataset)\n",
    "\n",
    "\n",
    "\n",
    "posDataset, negDataset = ut.preprocessImages(positiveDataset, negativeDataset)\n",
    "\n",
    "print(f\"Positive Dataset Shape: {posDataset.shape}\")\n",
    "print(f\"Negative Dataset Shape: {negDataset.shape}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minFeatureWidth = 4\n",
    "maxFeatureWidth = 16\n",
    "minFeatureHeight = 4\n",
    "maxFeatureHeight = 16\n",
    "nClassifiers = 50\n",
    "threshold = 0.5\n",
    "\n",
    "classifiersToBeUsed = []\n",
    "try :\n",
    "    print(\"Loading classifiers...\")\n",
    "    classifiersToBeUsed = np.load(\"./classifiers.npy\", allow_pickle=True)\n",
    "except Exception as e:\n",
    "    # print(e)\n",
    "    print(\"No classifiers found, creating new classifiers...\")\n",
    "    classifier = ab.AdaBoost()\n",
    "    start = time.time()\n",
    "    classifiersToBeUsed = classifier.learn(posDataset, negDataset,threshold,minFeatureWidth,minFeatureHeight,maxFeatureWidth,maxFeatureHeight, nClassifiers)\n",
    "    end = time.time()\n",
    "    classifiersToBeUsed = np.array(classifiersToBeUsed)\n",
    "    np.save(\"./classifiers.npy\", classifiersToBeUsed)\n",
    "    print(\"Time taken to train the classifier: \", end-start)\n",
    "\n",
    "print(\"Classifiers loaded successfully\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataSet = np.load(\"./Dataset/testFaces.npy\")\n",
    "testDataSetTarget = np.load(\"./Dataset/testTargets.npy\")\n",
    "#convert to int \n",
    "testDataSetTarget = testDataSetTarget.astype(int)\n",
    "\n",
    "#print the first 10 images in the test dataset\n",
    "# for i in range(10):\n",
    "#     io.imshow(testDataSet[i])\n",
    "#     io.show()\n",
    "\n",
    "# select random 10 images from the test dataset from the first axis\n",
    "# numbers = np.arange(0, len(testDataSet))\n",
    "# indices = np.random.choice(numbers, 10, replace=False)\n",
    "# testDataSet = testDataSet[indices]\n",
    "# testDataSetTarget = testDataSetTarget[indices]\n",
    "\n",
    "# print(\"Selected 10 random images from the test dataset\")\n",
    "# for i in range(10):\n",
    "#     io.imshow(testDataSet[i])\n",
    "#     io.show()\n",
    "#     print(\"Target: \", testDataSetTarget[i])\n",
    "\n",
    "\n",
    "\n",
    "#get integral images\n",
    "ii = np.array([ut.integralImage(test) for test in testDataSet])\n",
    "\n",
    "i = 0\n",
    "correctCount = 0\n",
    "firstWrong = 5\n",
    "for test in ii:\n",
    "    predicted = ut.getVotes(np.array(classifiersToBeUsed), test)\n",
    "    if predicted == testDataSetTarget[i]:\n",
    "        correctCount += 1\n",
    "    else:\n",
    "        if firstWrong > 0:\n",
    "            print(\"Predicted: \", predicted)\n",
    "            print(\"Target: \", testDataSetTarget[i])\n",
    "            io.imshow(testDataSet[i])\n",
    "            io.show()\n",
    "            firstWrong -= 1\n",
    "    i += 1\n",
    "\n",
    "print(\"Accuracy: \", correctCount/len(testDataSet) * 100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22323b844011101ed249661b7dd2cae934f6b78b31436e3431524c9d958c4c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
