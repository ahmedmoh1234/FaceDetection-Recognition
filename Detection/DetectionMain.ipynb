{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import skimage as sk\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "from unitTesting import UnitTest\n",
    "import adaboost.adaboost as ab\n",
    "import utilitis as ut"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Integral image test PASSED\n",
      "Total number of features = 273312\n",
      "Determine features test FAILED. No of features : 273,312\n",
      "Calculate sum test 1 PASSED\n",
      "Calculate sum test 2 PASSED\n",
      "Calculate sum test 3 PASSED\n",
      "Feature value test 1 PASSED\n",
      "Feature value test 2 PASSED\n"
     ]
    }
   ],
   "source": [
    "img = io.imread('./test.jpg')\n",
    "img = rgb2gray(img)\n",
    "unitTesting = UnitTest(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading positive dataset...\n",
      "Loading negative dataset...\n",
      "Positive Dataset Shape: (300, 24, 24)\n",
      "Negative Dataset Shape: (240, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#load positive dataset\n",
    "try:\n",
    "    print(\"Loading positive dataset...\")\n",
    "    positiveDataset = np.load(\"./Dataset/posTrain.npy\")\n",
    "except:\n",
    "    print(\"No dataset found, creating new dataset...\")\n",
    "    positiveDataset = np.load(\"./Dataset/olivetti_faces.npy\")\n",
    "    personID = np.load(\"./Dataset/olivetti_faces_target.npy\")\n",
    "\n",
    "\n",
    "    #resize images to 24x24\n",
    "    newPositiveDataset = np.empty(shape=(positiveDataset.shape[0], 24, 24))\n",
    "    for i in range(len(positiveDataset)):\n",
    "        newImg = np.array(positiveDataset[i])\n",
    "        \n",
    "        finalImg = resize(newImg, (24, 24))\n",
    "        newPositiveDataset[i] = finalImg\n",
    "\n",
    "    positiveDataset = newPositiveDataset\n",
    "\n",
    "    # for i in range(10):\n",
    "    #     io.imshow(positiveDataset[i])\n",
    "    #     io.show()\n",
    "\n",
    "    # print(positiveDataset.shape)\n",
    "\n",
    "    \n",
    "\n",
    "    # np.save(\"./Dataset/positiveDataset.npy\", positiveDataset)\n",
    "    # print(\"Positive Dataset saved\")\n",
    "\n",
    "#loading negative dataset\n",
    "try:\n",
    "    print(\"Loading negative dataset...\")\n",
    "    negativeDataset = np.load(\"./Dataset/negTrain.npy\")\n",
    "except:\n",
    "    print(\"No dataset found, creating new dataset...\")\n",
    "    directory = \"./Dataset/NegativeSet\"\n",
    "    negativeDataset = np.empty(shape=(len(os.listdir(directory)), 24, 24))\n",
    "    i = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            curImg = io.imread(os.path.join(directory, filename), as_gray=True)\n",
    "            newImg = resize(curImg, (24, 24))\n",
    "            negativeDataset[i] = newImg\n",
    "            i += 1\n",
    "    # negativeDataset = negativeDataset.reshape(len(os.listdir(directory)), 64, 64)\n",
    "    # print(negativeDataset.shape)\n",
    "    # np.save(\"./Dataset/negativeDataset.npy\", negativeDataset)\n",
    "    # print(\"Negative Dataset saved\")\n",
    "\n",
    "\n",
    "\n",
    "posDataset, negDataset = ut.preprocessImages(positiveDataset, negativeDataset)\n",
    "\n",
    "print(f\"Positive Dataset Shape: {posDataset.shape}\")\n",
    "print(f\"Negative Dataset Shape: {negDataset.shape}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading classifiers...\n",
      "No classifiers found, creating new classifiers...\n",
      "Calculating integral images...\n",
      "Done!\n",
      "\n",
      "Creating initial weights and labels...\n",
      "Done!\n",
      "\n",
      "Calculating all possible haar features...\n",
      "Total number of features = 121992\n",
      "Done!\n",
      "\n",
      "Calculating votes of all haar features for all samples...\n",
      "Done!\n",
      "\n",
      "Training 121992 classifiers...\n",
      " Training classifier 50 of 50...Time taken to train the classifier:  755.8560917377472\n",
      "Classifiers loaded successfully\n"
     ]
    }
   ],
   "source": [
    "minFeatureWidth = 4\n",
    "maxFeatureWidth = 16\n",
    "minFeatureHeight = 4\n",
    "maxFeatureHeight = 16\n",
    "nClassifiers = 50\n",
    "threshold = 0.5\n",
    "\n",
    "classifiersToBeUsed = []\n",
    "try :\n",
    "    print(\"Loading classifiers...\")\n",
    "    classifiersToBeUsed = np.load(\"./classifiers.npy\", allow_pickle=True)\n",
    "except Exception as e:\n",
    "    # print(e)\n",
    "    print(\"No classifiers found, creating new classifiers...\")\n",
    "    classifier = ab.AdaBoost()\n",
    "    start = time.time()\n",
    "    classifiersToBeUsed = classifier.learn(posDataset, negDataset,threshold,minFeatureWidth,minFeatureHeight,maxFeatureWidth,maxFeatureHeight, nClassifiers)\n",
    "    end = time.time()\n",
    "    classifiersToBeUsed = np.array(classifiersToBeUsed)\n",
    "    np.save(\"./classifiers.npy\", classifiersToBeUsed)\n",
    "    print(\"Time taken to train the classifier: \", end-start)\n",
    "\n",
    "print(\"Classifiers loaded successfully\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Dataset Shape: (160, 24, 24)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "The directory 'd:\\\\University\\\\Senior 2\\\\Fall 2022\\\\Image Processing\\\\Project\\\\FaceDetection-Recognition\\\\Detection\\\\trainImages' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [7], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[39m#Select the last 200 images from the test dataset\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m# testDataSet = testDataSet[200:]\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[39m#output all training images to the hard drive\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(posDataset)):\n\u001b[1;32m---> 13\u001b[0m     io\u001b[39m.\u001b[39;49mimsave(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./trainImages/\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m, posDataset[i])\n\u001b[0;32m     16\u001b[0m \u001b[39m#print the first 10 images in the test dataset\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m# for i in range(10):\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39m#     io.imshow(testDataSet[i])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[39m#get integral images\u001b[39;00m\n\u001b[0;32m     36\u001b[0m ii \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([ut\u001b[39m.\u001b[39mintegralImage(test) \u001b[39mfor\u001b[39;00m test \u001b[39min\u001b[39;00m testDataSet])\n",
      "File \u001b[1;32mc:\\Users\\Ahmed Ismail\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skimage\\io\\_io.py:143\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, plugin, check_contrast, **plugin_args)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[39mif\u001b[39;00m check_contrast \u001b[39mand\u001b[39;00m is_low_contrast(arr):\n\u001b[0;32m    142\u001b[0m     warn(\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m is a low contrast image\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m fname)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m call_plugin(\u001b[39m'\u001b[39m\u001b[39mimsave\u001b[39m\u001b[39m'\u001b[39m, fname, arr, plugin\u001b[39m=\u001b[39mplugin, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mplugin_args)\n",
      "File \u001b[1;32mc:\\Users\\Ahmed Ismail\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\skimage\\io\\manage_plugins.py:207\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not find the plugin \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m    205\u001b[0m                            (plugin, kind))\n\u001b[1;32m--> 207\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ahmed Ismail\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imageio\\v2.py:238\u001b[0m, in \u001b[0;36mimwrite\u001b[1;34m(uri, im, format, **kwargs)\u001b[0m\n\u001b[0;32m    236\u001b[0m imopen_args \u001b[39m=\u001b[39m decypher_format_arg(\u001b[39mformat\u001b[39m)\n\u001b[0;32m    237\u001b[0m imopen_args[\u001b[39m\"\u001b[39m\u001b[39mlegacy_mode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 238\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39m\u001b[39mwi\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mimopen_args) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m    239\u001b[0m     \u001b[39mreturn\u001b[39;00m file\u001b[39m.\u001b[39mwrite(im, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ahmed Ismail\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imageio\\core\\imopen.py:118\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     request\u001b[39m.\u001b[39mformat_hint \u001b[39m=\u001b[39m format_hint\n\u001b[0;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     request \u001b[39m=\u001b[39m Request(uri, io_mode, format_hint\u001b[39m=\u001b[39;49mformat_hint, extension\u001b[39m=\u001b[39;49mextension)\n\u001b[0;32m    120\u001b[0m source \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<bytes>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(uri, \u001b[39mbytes\u001b[39m) \u001b[39melse\u001b[39;00m uri\n\u001b[0;32m    122\u001b[0m \u001b[39m# fast-path based on plugin\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ahmed Ismail\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imageio\\core\\request.py:248\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[1;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Request.Mode: \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    247\u001b[0m \u001b[39m# Parse what was given\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_uri(uri)\n\u001b[0;32m    250\u001b[0m \u001b[39m# Set extension\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[39mif\u001b[39;00m extension \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Ahmed Ismail\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\imageio\\core\\request.py:412\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    410\u001b[0m dn \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(fn)\n\u001b[0;32m    411\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(dn):\n\u001b[1;32m--> 412\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe directory \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m dn)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: The directory 'd:\\\\University\\\\Senior 2\\\\Fall 2022\\\\Image Processing\\\\Project\\\\FaceDetection-Recognition\\\\Detection\\\\trainImages' does not exist"
     ]
    }
   ],
   "source": [
    "testDataSet = np.load(\"./Dataset/testMix.npy\")\n",
    "testDataSetTarget = np.load(\"./Dataset/testTargets.npy\")\n",
    "#convert to int \n",
    "testDataSetTarget = testDataSetTarget.astype(int)\n",
    "\n",
    "print(f\"Test Dataset Shape: {testDataSet.shape}\")\n",
    "\n",
    "#Select the last 200 images from the test dataset\n",
    "# testDataSet = testDataSet[200:]\n",
    "\n",
    "#output all training images to the hard drive\n",
    "# for i in range(len(posDataset)):\n",
    "#     io.imsave(f\"./trainImages/{i}.jpg\", posDataset[i])\n",
    "\n",
    "\n",
    "#print the first 10 images in the test dataset\n",
    "# for i in range(10):\n",
    "#     io.imshow(testDataSet[i])\n",
    "#     io.show()\n",
    "\n",
    "# select random 10 images from the test dataset from the first axis\n",
    "# numbers = np.arange(0, len(testDataSet))\n",
    "# indices = np.random.choice(numbers, 10, replace=False)\n",
    "# testDataSet = testDataSet[indices]\n",
    "# testDataSetTarget = testDataSetTarget[indices]\n",
    "\n",
    "# print(\"Selected 10 random images from the test dataset\")\n",
    "# for i in range(10):\n",
    "#     io.imshow(testDataSet[i])\n",
    "#     io.show()\n",
    "#     print(\"Target: \", testDataSetTarget[i])\n",
    "\n",
    "\n",
    "\n",
    "#get integral images\n",
    "ii = np.array([ut.integralImage(test) for test in testDataSet])\n",
    "\n",
    "i = 0\n",
    "correctCount = 0\n",
    "firstWrong = 5\n",
    "for test in ii:\n",
    "    predicted = ut.getVotes(np.array(classifiersToBeUsed), test)\n",
    "    if predicted == testDataSetTarget[i]:\n",
    "        correctCount += 1\n",
    "    else:\n",
    "        if firstWrong > 0:\n",
    "            print(\"Predicted: \", predicted)\n",
    "            print(\"Target: \", testDataSetTarget[i])\n",
    "            # io.imshow(testDataSet[i])\n",
    "            # io.show()\n",
    "            firstWrong -= 1\n",
    "    i += 1\n",
    "\n",
    "print(\"Accuracy: \", correctCount/len(testDataSet) * 100, \"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22323b844011101ed249661b7dd2cae934f6b78b31436e3431524c9d958c4c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
