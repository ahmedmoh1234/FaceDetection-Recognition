{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import skimage.io as io\n",
    "from skimage.color import rgb2gray\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- LOAD OLIVETTI DATASET ---------------------------- #\n",
    "\n",
    "def load_dataset():\n",
    "    dataset = fetch_olivetti_faces(data_home='D:\\Senior II\\Image Processing\\Project\\Datasets/Olivietta Dataset', shuffle=True, random_state=47)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info_from_dataset(dataset, verbose=False):\n",
    "    \n",
    "    '''\n",
    "    Returns: \n",
    "        - images: ndarray(m, height, width): the images of the dataset\n",
    "        - m: int: the number of images in the dataset\n",
    "        - height: int: the height of each image\n",
    "        - width: int: the width of each image\n",
    "        - total_images: int:  the total number of images in the dataset\n",
    "        - n_features: int: the number of features of each image = height * width\n",
    "        - y: ndarray(m,): the labels of the images\n",
    "        - num_people: int the number of people in the dataset\n",
    "    '''\n",
    "    \n",
    "    images = dataset.images\n",
    "\n",
    "    m = images.shape[0]\n",
    "    if(verbose):\n",
    "        print('Images shape:',images.shape)\n",
    "\n",
    "    total_images, height, width = images.shape\n",
    "    if(verbose):\n",
    "        print(f'Each image has size: {height} x {width}')\n",
    "        print(70* '-')\n",
    "\n",
    "    n_features = height*width\n",
    "    if(verbose):\n",
    "        print(f'N^2 = n_features = h x w = {n_features}')\n",
    "        print(70* '-')\n",
    "\n",
    "    y = dataset.target\n",
    "    if(verbose):\n",
    "        print('y has shape:', y.shape)\n",
    "\n",
    "    num_people = np.max(y) + 1\n",
    "    if(verbose):\n",
    "        print('Number of people =', num_people)\n",
    "\n",
    "    return images, m, height, width, total_images, n_features, y, num_people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------- CREATE PEOPLE DICTIONARY -----------------------#\n",
    "\n",
    "\n",
    "def create_people_dict(total_images, num_people, y):\n",
    "    # Key: person ID\n",
    "    # Value: List of all person images indices\n",
    "    person_image_dict = dict()\n",
    "\n",
    "    for image_index in range(total_images):\n",
    "        if (y[image_index] not in person_image_dict.keys()):\n",
    "            person_image_dict[y[image_index]] = [image_index]\n",
    "        else:\n",
    "            person_image_dict[y[image_index]].append(image_index)\n",
    "    return person_image_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ VIEW RANDOM IMAGE ------------------ #\n",
    "\n",
    "def view_rand_image(images, m):\n",
    "    index = int(random.random() * m)\n",
    "    index = 0\n",
    "    image = images[index,:,:]\n",
    "    # name = target_names[y[index]]\n",
    "\n",
    "    # print(name)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- GET FLATTEN IMAGES --------------------- #\n",
    "\n",
    "def get_flattened_images(images, m, height, width, verbose=False):\n",
    "    # Flatten images array\n",
    "    # Each column is an image\n",
    "\n",
    "    # N^2 * M\n",
    "    flattened_images = images.reshape(m, -1).T\n",
    "\n",
    "    if(verbose):\n",
    "        print(f'Shape of training images after flattening: {flattened_images.shape}')\n",
    "    \n",
    "    return flattened_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- CALCULATE AVERAGE IMAGE ----------------- #\n",
    "\n",
    "def get_average_image(flattened_images, height, width, verbose=False):\n",
    "    # In all corresponding pixels in all images, we calculate the average\n",
    "\n",
    "    # N^2 * 1\n",
    "    average_image = np.mean(flattened_images, axis = 1)[:,np.newaxis]\n",
    "    if(verbose):\n",
    "        print(f'Average image has shape: {average_image.shape}')\n",
    "        plt.imshow(average_image.reshape(height,width), cmap='gray', title='Average Image')\n",
    "        plt.show()\n",
    "    return average_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------- GET DIFFERENCE IMAGES --------------------------------#\n",
    "\n",
    "def get_difference_images(flattened_images, average_image, verbose=False):\n",
    "    # Subtract the average image from all images\n",
    "    # This is done to remove the average face from all images\n",
    "    # N^2 * M\n",
    "    difference_images = flattened_images - average_image\n",
    "    if(verbose):\n",
    "        print(f'Shape after subtracting average face: {difference_images.shape}')\n",
    "    return difference_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------- SHOW ONE DIFFERENCE IMAGE AND COMPARE TO ORIGINAL --------------------- #\n",
    "\n",
    "def show_difference_image(difference_images, train_images, height, width, m):\n",
    "    # Show one difference image and compare to original\n",
    "    index = int(random.random() * m)\n",
    "\n",
    "    plt.imshow(difference_images[:,index].reshape(height, width), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    # Print original image\n",
    "    plt.imshow(train_images[index,:,:], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------- GET COVARIANCE MATRIX --------------------- #\n",
    "\n",
    "def get_covariance_matrix(m, n_features, difference_images, verbose=False):\n",
    "    # C = A * A^T where A = difference_images\n",
    "    # N^2 * M\n",
    "    A = difference_images\n",
    "\n",
    "    if (m > n_features):\n",
    "        # N^2 * N^2\n",
    "        covariance_matrix = np.matmul(difference_images, difference_images.T)\n",
    "        if(verbose):\n",
    "            print('Shape of covariance matrix = N^2 * N^2 = ', covariance_matrix.shape)\n",
    "        return covariance_matrix\n",
    "        \n",
    "    else:\n",
    "        # M * M\n",
    "        covariance_matrix = np.matmul(difference_images.T, difference_images)\n",
    "        if(verbose):\n",
    "            print('Shape of covariance matrix = M * M = ', covariance_matrix.shape)\n",
    "        return covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------- GET EIGENVALUES AND EIGENVECTORS --------------------------------- #\n",
    "\n",
    "def eigenvalues_eigenfaces(covariance_matrix, difference_images, verbose=False):\n",
    "    # M eigenvalues and M eigenvectors\n",
    "    # where M is the number of examples\n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    \n",
    "    if(verbose):\n",
    "        print('Shape of eigenvalues:', eigenvalues.shape)\n",
    "        print('Shape of eigenvectors before matrix multiplication:', eigenvectors.shape)\n",
    "\n",
    "    # Try to remove\n",
    "    eigenfaces = np.matmul(difference_images, eigenvectors)\n",
    "\n",
    "    if(verbose):\n",
    "        print('Shape of eigenfaces after matrix multiplication:', eigenfaces.shape)\n",
    "\n",
    "    return eigenvalues, eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------- NORMALIZE eigenfaces --------------------------------- #\n",
    "\n",
    "def normalize_eigenfaces(eigenfaces, verbose=False):\n",
    "    eigenfaces = eigenfaces / np.linalg.norm(eigenfaces, axis=0)\n",
    "    if(verbose):\n",
    "        print('Shape of eigenfaces after normalization:', eigenfaces.shape)\n",
    "    return eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ SORT eigenfaces ------------------------ #\n",
    "\n",
    "def sort_eigenvalues_eigenfaces(eigenvalues, eigenfaces):\n",
    "    # Get top K eigenfaces\n",
    "    indices_of_top_eigenvalues = np.argsort(-eigenvalues)\n",
    "    eigenvalues = eigenvalues[indices_of_top_eigenvalues]\n",
    "    eigenfaces = eigenfaces[:, indices_of_top_eigenvalues]\n",
    "    return eigenvalues, eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------- CALCULATE K --------------------------------- #\n",
    "\n",
    "def calculate_K(eigenvalues, m, variance = 0.8, verbose = False):\n",
    "    #Calculate the number of components to preserve specified variance\n",
    "    K = m\n",
    "    for ii, eigen_value_cumsum in enumerate(np.cumsum(eigenvalues) / np.sum(eigenvalues)):\n",
    "        if eigen_value_cumsum > variance:\n",
    "            K = ii\n",
    "            break\n",
    "\n",
    "    if(verbose):\n",
    "        print(f'Number of components to preserve {variance*100}% of the variance = {K}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------- SELECT K TOP eigenfaces --------------------------------- #\n",
    "\n",
    "\n",
    "def select_K_top_eigenfaces(eigenvalues, eigenfaces, K, verbose=False):\n",
    "    # Select only K eigenfaces\n",
    "    eigenvalues = eigenvalues[:K].copy()\n",
    "    eigenfaces = eigenfaces[:, :K].copy()\n",
    "\n",
    "    if(verbose):\n",
    "        print('Shape of eigenvalues after selecting top K:', eigenvalues.shape)\n",
    "        # N^2 * K\n",
    "        print('Shape of eigenfaces after selecting top K:', eigenfaces.shape)\n",
    "    return eigenvalues,eigenfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------ SHOW EIGENFACES ------------------------ #\n",
    "\n",
    "def show_eigenfaces(eigenfaces, height, width, K, num_show=16):\n",
    "    # Show eigenfaces\n",
    "    for i in range(min(K, num_show)):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(eigenfaces[:,i].reshape(height, width), cmap='gray')\n",
    "        plt.title(f'Eigenface {i+1}')\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ SHOW A RANDOM EIGENFACE ------------------------ #\n",
    "\n",
    "def show_random_eigenface(eigenfaces, height, width, m):\n",
    "    index = int(random.random() * m)\n",
    "    plt.imshow(eigenfaces[:,index].reshape(height, width), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ CALCULATE OMEGAS ------------------------ #\n",
    "\n",
    "def get_omegas(difference_images, eigenfaces, verbose=False):\n",
    "    omegas = []\n",
    "    for image in difference_images.T:\n",
    "        omegas.append(np.dot(image, eigenfaces))\n",
    "    omegas = np.array(omegas)\n",
    "    if(verbose):\n",
    "        print('Shape of omegas:', omegas.shape)\n",
    "    return omegas"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(omegas, test_image, average_image, eigenfaces, height, width, threshold):\n",
    "    # Predict the class of a test image\n",
    "    # Calculate omega for test image\n",
    "    omega = np.matmul((test_image - average_image).T, eigenfaces)\n",
    "\n",
    "    # Calculate distance between omega and all omegas\n",
    "    distances = np.linalg.norm(omegas - omega, axis=1)\n",
    "\n",
    "    # Get the index of the minimum distance\n",
    "    index = np.argmin(distances)\n",
    "\n",
    "    #Get min distance\n",
    "    min_distance = distances[index]\n",
    "\n",
    "    if(min_distance < threshold):\n",
    "        return index\n",
    "    else:\n",
    "        return -1 # Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image(image, width, height):\n",
    "    #if image is RGB, convert to grayscale\n",
    "    if len(image.shape) > 2:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    #resize image to width*height\n",
    "    image = cv2.resize(image, (width, height))\n",
    "    #flatten image if it is not already\n",
    "    if (len(image.shape) == 1):\n",
    "        image = image[:, np.newaxis]\n",
    "    elif (image.shape[1] != 1 or image.shape[0] != 1):\n",
    "        image = image.reshape(-1, 1)\n",
    "    \n",
    "    #Show image\n",
    "    plt.imshow(image.reshape(height, width), cmap='gray', label='Input image')\n",
    "    plt.show()\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognizer_main(input_image):\n",
    "    dataset = load_dataset()\n",
    "    images, m, height, width, total_images, n_features, y, num_people = extract_info_from_dataset(dataset)\n",
    "    input_image = convert_image(input_image, width, height)\n",
    "    #people_dict = create_people_dict(total_images, num_people, y)\n",
    "    flattened_images = get_flattened_images(images, m, height, width)\n",
    "    average_image = get_average_image(flattened_images, height, width)\n",
    "    difference_images = get_difference_images(flattened_images, average_image)\n",
    "    covariance_matrix = get_covariance_matrix(m, n_features, difference_images)\n",
    "    eigenvalues, eigenfaces = eigenvalues_eigenfaces(covariance_matrix, difference_images)\n",
    "    eigenfaces = normalize_eigenfaces(eigenfaces)\n",
    "    eigenvalues, eigenfaces = sort_eigenvalues_eigenfaces(eigenvalues, eigenfaces)\n",
    "    K = calculate_K(eigenvalues, m)\n",
    "    eigenvalues, eigenfaces = select_K_top_eigenfaces(eigenvalues, eigenfaces, K)\n",
    "    omegas = get_omegas(difference_images, eigenfaces)\n",
    "    predicted_index = predict(omegas, input_image, average_image, eigenfaces, height, width, 7)\n",
    "    if (predicted_index == -1):\n",
    "        print('Unknown face')\n",
    "    else:\n",
    "        # print('Predicted index:', predicted_index)\n",
    "        print('Known face')\n",
    "        #show predicted image\n",
    "        plt.imshow(images[predicted_index], cmap='gray', label='Predicted image')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'd:\\Senior II\\Image Processing\\Project\\FaceDetection-Recognition\\naderTest.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Senior II\\Image Processing\\Project\\FaceDetection-Recognition\\main recognizer.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Senior%20II/Image%20Processing/Project/FaceDetection-Recognition/main%20recognizer.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m naderTest \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39;49mimread(\u001b[39m'\u001b[39;49m\u001b[39mnaderTest.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Senior%20II/Image%20Processing/Project/FaceDetection-Recognition/main%20recognizer.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m recognizer_main(naderTest)\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skimage\\io\\_io.py:53\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m         plugin \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtifffile\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     52\u001b[0m \u001b[39mwith\u001b[39;00m file_or_url_context(fname) \u001b[39mas\u001b[39;00m fname:\n\u001b[1;32m---> 53\u001b[0m     img \u001b[39m=\u001b[39m call_plugin(\u001b[39m'\u001b[39m\u001b[39mimread\u001b[39m\u001b[39m'\u001b[39m, fname, plugin\u001b[39m=\u001b[39mplugin, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mplugin_args)\n\u001b[0;32m     55\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(img, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skimage\\io\\manage_plugins.py:207\u001b[0m, in \u001b[0;36mcall_plugin\u001b[1;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not find the plugin \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m for \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m    205\u001b[0m                            (plugin, kind))\n\u001b[1;32m--> 207\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\skimage\\io\\_plugins\\imageio_plugin.py:15\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m@wraps\u001b[39m(imageio_imread)\n\u001b[0;32m     14\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(imageio_imread(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs))\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imageio\\v2.py:200\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m imopen_args \u001b[39m=\u001b[39m decypher_format_arg(\u001b[39mformat\u001b[39m)\n\u001b[0;32m    198\u001b[0m imopen_args[\u001b[39m\"\u001b[39m\u001b[39mlegacy_mode\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[39mwith\u001b[39;00m imopen(uri, \u001b[39m\"\u001b[39m\u001b[39mri\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mimopen_args) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m    201\u001b[0m     \u001b[39mreturn\u001b[39;00m file\u001b[39m.\u001b[39mread(index\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imageio\\core\\imopen.py:118\u001b[0m, in \u001b[0;36mimopen\u001b[1;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m     request\u001b[39m.\u001b[39mformat_hint \u001b[39m=\u001b[39m format_hint\n\u001b[0;32m    117\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     request \u001b[39m=\u001b[39m Request(uri, io_mode, format_hint\u001b[39m=\u001b[39;49mformat_hint, extension\u001b[39m=\u001b[39;49mextension)\n\u001b[0;32m    120\u001b[0m source \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m<bytes>\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(uri, \u001b[39mbytes\u001b[39m) \u001b[39melse\u001b[39;00m uri\n\u001b[0;32m    122\u001b[0m \u001b[39m# fast-path based on plugin\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imageio\\core\\request.py:248\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[1;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid Request.Mode: \u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    247\u001b[0m \u001b[39m# Parse what was given\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_uri(uri)\n\u001b[0;32m    250\u001b[0m \u001b[39m# Set extension\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[39mif\u001b[39;00m extension \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\EGYPT\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\imageio\\core\\request.py:407\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[39mif\u001b[39;00m is_read_request:\n\u001b[0;32m    405\u001b[0m     \u001b[39m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(fn):\n\u001b[1;32m--> 407\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo such file: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m fn)\n\u001b[0;32m    408\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    409\u001b[0m     \u001b[39m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     dn \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(fn)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'd:\\Senior II\\Image Processing\\Project\\FaceDetection-Recognition\\naderTest.jpg'"
     ]
    }
   ],
   "source": [
    "naderTest = io.imread('naderTest.jpg')\n",
    "recognizer_main(naderTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20aebf7f160902ad9dd8cbfe460d54a7c92755b430d8a2756048c9f24f1ce0aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
